# ğŸ“Š Guide d'Utilisation JMeter - Variante D

## ğŸ¯ Fichiers CrÃ©Ã©s

- `scenario1-read-heavy-variante-d.jmx` - ScÃ©nario READ-heavy
- `scenario2-join-filter-variante-d.jmx` - ScÃ©nario JOIN-filter
- `scenario3-mixed-variante-d.jmx` - ScÃ©nario MIXED
- `scenario4-heavy-body-variante-d.jmx` - ScÃ©nario HEAVY-body
- `ids.csv` - Fichier CSV avec les IDs pour les tests

## ğŸš€ Comment Utiliser les Fichiers JMeter

### Ã‰tape 1 : Ouvrir JMeter

```bash
jmeter
```

### Ã‰tape 2 : Ouvrir un fichier de test

1. Dans JMeter : **File â†’ Open**
2. Naviguer vers : `service-d/jmeter/`
3. SÃ©lectionner un fichier `.jmx` (ex: `scenario1-read-heavy-variante-d.jmx`)

### Ã‰tape 3 : VÃ©rifier la Configuration

1. **HTTP Request Defaults** :
   - Server Name : `localhost`
   - Port Number : `8083` âœ… (Variante D)

2. **CSV Data Set Config** :
   - Filename : VÃ©rifier que le chemin vers `ids.csv` est correct
   - Variable Names : `categoryId,itemId`

3. **Thread Group** :
   - VÃ©rifier les paramÃ¨tres (threads, ramp-up, durÃ©e)

### Ã‰tape 4 : Lancer le Test

1. **DÃ©sactiver les listeners lourds** (View Results Tree) pendant les runs
2. Cliquer sur le bouton **â–¶ï¸ (Run)** en haut
3. Attendre la fin du test (selon la durÃ©e configurÃ©e)

### Ã‰tape 5 : Consulter les RÃ©sultats

AprÃ¨s le test, consulter :
- **Summary Report** : Vue d'ensemble avec RPS, latence moyenne, erreurs
- **Aggregate Report** : Statistiques dÃ©taillÃ©es (min, max, moyenne, p50, p95, p99)

## ğŸ“‹ Les 4 ScÃ©narios

### ScÃ©nario 1 : READ-heavy (relation incluse)
- **Fichier** : `scenario1-read-heavy-variante-d.jmx`
- **Mix** : 50% items list, 20% items by category, 20% cat->items, 10% cat list
- **Threads** : 50 â†’ 100 â†’ 200 (utiliser Stepping Thread Group)
- **Ramp-up** : 60s
- **DurÃ©e** : 10 min/palier

### ScÃ©nario 2 : JOIN-filter ciblÃ©
- **Fichier** : `scenario2-join-filter-variante-d.jmx`
- **Mix** : 70% items?categoryId, 30% item id
- **Threads** : 60 â†’ 120
- **Ramp-up** : 60s
- **DurÃ©e** : 8 min/palier

### ScÃ©nario 3 : MIXED (Ã©critures)
- **Fichier** : `scenario3-mixed-variante-d.jmx`
- **Mix** : GET/POST/PUT/DELETE sur items + categories
- **Threads** : 50 â†’ 100
- **Ramp-up** : 60s
- **DurÃ©e** : 10 min/palier

### ScÃ©nario 4 : HEAVY-body
- **Fichier** : `scenario4-heavy-body-variante-d.jmx`
- **Mix** : POST/PUT items 5 KB
- **Threads** : 30 â†’ 60
- **Ramp-up** : 60s
- **DurÃ©e** : 8 min/palier

## ğŸ“Š MÃ©triques Ã  Noter

Pour chaque scÃ©nario, noter dans le tableau T2 :

- **RPS** (Requests Per Second) : Dans Summary Report â†’ Throughput
- **p50** (ms) : 50th percentile latency
- **p95** (ms) : 95th percentile latency  
- **p99** (ms) : 99th percentile latency
- **Err %** : Error percentage

## âš ï¸ Points Importants

1. **DÃ©sactiver View Results Tree** pendant les runs (trop lourd)
2. **Garder Summary Report et Aggregate Report** activÃ©s
3. **VÃ©rifier que l'application tourne** sur le port 8083 avant de lancer
4. **Un test Ã  la fois** pour Ã©viter la surcharge

## ğŸ”„ RÃ©pÃ©ter pour les Autres Variantes

Pour tester les variantes A et C :
1. Modifier le **Port Number** dans HTTP Request Defaults :
   - Variante A : `8081`
   - Variante C : `8082`
   - Variante D : `8083` âœ…
2. Sauvegarder avec un nom diffÃ©rent
3. Relancer le test

## ğŸ“ Exemple de RÃ©sultats Attendus

Dans **Summary Report**, vous devriez voir :
- **Label** : Nom de la requÃªte
- **Samples** : Nombre de requÃªtes
- **Average** : Temps moyen (ms)
- **Min/Max** : Temps min/max (ms)
- **Error %** : Pourcentage d'erreurs
- **Throughput** : RPS (Requests Per Second)

Bon test ! ğŸš€

